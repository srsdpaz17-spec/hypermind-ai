import OpenAI from "openai";

export const config = {
  runtime: "edge",
};

export default async function handler(req) {
  try {
    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });

    const { message, mode } = await req.json();

    let result;

    if (mode === "chat") {
      const completion = await openai.chat.completions.create({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: message }]
      });
      result = completion.choices[0].message.content;
    }

    if (mode === "image") {
      const img = await openai.images.generate({
        model: "gpt-image-1",
        prompt: message
      });
      result = img.data[0].url;
    }

    if (mode === "voice") {
      const audio = await openai.audio.speech.create({
        model: "gpt-4o-mini-tts",
        voice: "alloy",
        input: message
      });
      const buffer = Buffer.from(await audio.arrayBuffer()).toString("base64");
      result = `data:audio/mp3;base64,${buffer}`;
    }

    if (mode === "video") {
      const response = await openai.videos.create({
        model: "gpt-video-1",
        prompt: message
      });
      result = response.data[0].url;
    }

    return new Response(JSON.stringify({ result }), {
      headers: {
        "Content-Type": "application/json",
        "Access-Control-Allow-Origin": "*",
        "Access-Control-Allow-Methods": "POST, OPTIONS",
        "Access-Control-Allow-Headers": "Content-Type"
      }
    });

  } catch (err) {
    return new Response(JSON.stringify({ error: err.message }), {
      status: 500,
      headers: { "Content-Type": "application/json" }
    });
  }
}
